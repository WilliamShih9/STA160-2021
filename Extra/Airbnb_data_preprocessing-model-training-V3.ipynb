{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import geohash as gh\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Airbnb_NYC_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep the missing values for `name`, `host_name`, since we are not going to using these variables in the model anyways. Even if we were, it may be worth it to keep them in the model to decide what the output of a null host_name would be.\n",
    "As for `last_review` and `reviews_per_month`, we believe that `last_month` is a variable that we would never include in the model. For `reviews_per_month`, we can replace all the missing values to 0, because 0 should be the correct value if a review has never been made for that listing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empty values for name, host_name, and last reviews can be dropped, since they seem non-menaingful to impute. We can replace the empty values for reviews per month with 0 values, becuase this means there is no review per month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_per_month'] = df['reviews_per_month'].fillna(0.00)\n",
    "df['name'] = df['name'].fillna('')\n",
    "df['host_name'] = df['host_name'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check missing values again \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Omit extreme outliers and invalid values\n",
    "\n",
    "There are also be some erroneous values in the dataset. For example, there are instances where the price is 10,000 per day despite being a single private room.\n",
    "\n",
    "For `price`, we omit from the dataset if the price is above 3,000 per day or costs 0 per day. For `minimum_nights`, we omit if the number of minimum nights is above 60 days per month. For `reviews_per_month`, we omit if the number is above 15 per month, as it is very unlikely a listing could get 15 reviews a month, which is a review every 2 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (6,3))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax1.boxplot(df['price'])\n",
    "ax1.set_yscale('log')\n",
    "ax1.axhline(y = 1000)\n",
    "ax1.set_xticklabels(['Price'])\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ax2.set_yscale('log')\n",
    "ax2.boxplot(df['minimum_nights'])\n",
    "ax2.set_xticklabels(['Minimum Nights'])\n",
    "ax2.axhline(y = 60)\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "ax3.set_yscale('log')\n",
    "ax3.axhline(y = 15)\n",
    "ax3.boxplot(df['reviews_per_month'])\n",
    "ax3.set_xticklabels(['Reviews Per Month'])\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Box Plot and Extreme Outlier Cutoff (Blue Line)\", y = 0.95)\n",
    "plt.grid(axis = 'y')\n",
    "plt.subplots_adjust(top = 0.85)\n",
    "plt.savefig('outlier.png', dpi = 400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_omit = df[(df['price'] > 0) & (df['price'] <= 1000) & (df['minimum_nights'] <= 60) & (df['reviews_per_month'] <= 15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 What are some components that need to take into considerations for house price?\n",
    "\n",
    "geography (`latitude`, `longitude`), `minimum_nights`, `number_of_reviews`, `reviews_per_month`, `calculated_host_listings_count`, `availability_365`. Thus we can exclude `id`, `host_id`, `last_review` from our considerations for training data. We also exclude `neigbourhood_group` from our analysis as we believe this too closely overlaps with coordinate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training data \n",
    "# drop unrelated information\n",
    "# neighborhood has the same information as latitude and longitude, thus enighborhood can be dropped\n",
    "df_relevant = df_omit.drop(['id','name', 'host_name', 'host_id','neighbourhood','last_review'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of unique values in each columne to decide what processing technique to use \n",
    "df_relevant.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 One hot encoding for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_relevant['room_type'].unique())\n",
    "print(df_relevant['neighbourhood_group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the number of unique values and data type for each column. We can apply the following encoding method for text preprocessing: \n",
    "\n",
    "1. one hot encoding for neighbor group\n",
    "2. create grouping for latitude and longitude first? then encode?\n",
    "3.label encode for room type since size matters\n",
    "4. conduct normalization/ standardization for all continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude label\n",
    "df_relevant.drop(['price'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant_encode = pd.get_dummies(df_relevant, prefix = ['neighbourhood_group', 'room_type'], columns = ['neighbourhood_group', 'room_type'])\n",
    "df_relevant_label = pd.get_dummies(df_relevant, prefix = ['neighbourhood_group'], columns = ['neighbourhood_group'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['Shared room','Private room','Entire home/apt'])\n",
    "df_relevant_label['room_type'] = le.transform(df_relevant_label['room_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Geohash for latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create geohash code for geographical data \n",
    "df_relevant_encode['geohash']=df_relevant_encode.apply(lambda x: gh.encode(x['latitude'], x['longitude'], precision=7), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop latltitude longitude\n",
    "df_relevant_encode.drop(['latitude', 'longitude'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant_encode.geohash.nunique()\n",
    "# there are 10442 unique geographical location, should apply target encoding later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col_names = df_relevant_encode.columns\n",
    "X = df_relevant_encode.values.tolist()\n",
    "y = df_omit['price'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Split Train and Test Data (2/3, 1/3 split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train data and test data for this one, with 67% in the training set and 33% in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test dataframe for target encoding later\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_test = pd.DataFrame(X_test)\n",
    "df_test_keep = df_test\n",
    "df_train.columns = X_col_names\n",
    "df_test.columns = X_col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Transform Continuous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `TargetEncoder` to encode the `geohash`. Also, transform the y-variable and x-variables if necessary into either normalized/standardized form.\n",
    "\n",
    "Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.\n",
    "\n",
    "Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# target encode on geolocations, since the amount of unique values are large\n",
    "# if we look at price as a target, each row with the unique value of geolocation would be replaced with the average price for the house\n",
    "encoder = ce.TargetEncoder(cols=['geohash'], smoothing=0, return_df=True)\n",
    "\n",
    "df_train['coded_geo'] = encoder.fit_transform(df_train['geohash'], y_train)\n",
    "df_test['coded_geo'] = encoder.transform(df_train['geohash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('geohash', axis=1, inplace= True)\n",
    "df_test.drop('geohash', axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out the y-variable could benefit from a log transformation, depending on what model we are using as the distribution of prices is close to a lognormal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one, two, three = stats.boxcox(y_train, alpha = 0.95)\n",
    "# print(three)\n",
    "#y_train = np.log(y_train)\n",
    "#y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate train and test dataframes again for normalization or stanadardization\n",
    "df_train['price'] = y_train\n",
    "df_test['price'] = y_test\n",
    "df_whole = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply standarization or normalization on continuous values based on the data distribution\n",
    "to_scale = ['minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "       'calculated_host_listings_count', 'availability_365','coded_geo']\n",
    "scaled_train = df_train.copy()\n",
    "scaled_test = df_test.copy()\n",
    "scaled_features = scaled_train[to_scale]\n",
    "scaler = preprocessing.StandardScaler().fit(scaled_features)\n",
    "scaled_train[to_scale] = scaler.transform(scaled_features)\n",
    "scaled_test[to_scale] = scaler.transform(scaled_test[to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is extra code in case room_type uses the label encode instead of one-hot encoding\n",
    "# scaler2 = preprocessing.StandardScaler().fit(df_relevant_label['room_type'].values.reshape(-1,1))\n",
    "# df_relevant_label['room_type'] = scaler2.transform(df_relevant_label['room_type'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.mean_, scaler.var_)\n",
    "# print(scaler2.mean_, scaler2.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaled_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation plot to decide variables \n",
    "scaled_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_X = scaled_train.loc[:, scaled_train.columns != 'price'].values.tolist()\n",
    "scaled_train_y = scaled_train['price'].tolist()\n",
    "\n",
    "scaled_test_X = scaled_test.loc[:, scaled_train.columns != 'price'].values.tolist()\n",
    "scaled_test_y = scaled_test['price'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions to do plotting \n",
    "# get the raw features importance (aggregate all dummies)\n",
    "def raw_feature_importance(importance_dataframe, num_pos, cate_list):\n",
    "    # numercial feature importance\n",
    "    num_importance = importance_dataframe.head(num_pos) \n",
    "    num_importance.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    cate_dict ={}\n",
    "    for i in cate_list:\n",
    "        summ = 0\n",
    "        for (idx, row) in importance_dataframe.iterrows():\n",
    "            if i in row.loc['Feature']:\n",
    "                summ += row.loc['Importance']\n",
    "        cate_dict[i] = summ \n",
    "    \n",
    "    cate_importance = pd.DataFrame.from_dict(cate_dict, orient='index')\n",
    "    cate_importance.rename(columns={0: 'Importance'}, inplace=True)\n",
    "    cate_importance.reset_index(inplace = True)\n",
    "    cate_importance.rename(index=str, columns={\"index\": \"Feature\"}, inplace = True)\n",
    "\n",
    "    raw_feature_importances = pd.concat([num_importance, cate_importance])\n",
    "    raw_feature_importances.sort_values(by=['Importance'], inplace = True, ascending=False)\n",
    "    return raw_feature_importances\n",
    "\n",
    "# feature importance\n",
    "def plot_feature_importance(rank_importance,left_limit, color, alpha, size_L, size_H, title):\n",
    "    plt.style.use('default')\n",
    "    fig, ax = plt.subplots(1,1) \n",
    "    ax.barh(range(len(rank_importance['Feature'][0:left_limit])),rank_importance[0:left_limit]['Importance'],color=color,alpha=alpha)\n",
    "    #ax.barh(rank_importance[0:left_limit]['Importance'],range(len(rank_importance['Feature'][0:left_limit])),color=color,alpha=alpha)\n",
    "    ax.set_yticks(range(rank_importance[0:left_limit].shape[0]))\n",
    "    ax.set_yticklabels(rank_importance[0:left_limit]['Feature'], rotation='horizontal', fontsize=12)    \n",
    "    ax.set_ylabel('Features', fontsize = 16)\n",
    "    ax.set_xlabel('Feature importance', fontsize = 16)\n",
    "    ax.set_title(title, fontsize = 16)\n",
    "    fig.set_size_inches(size_L, size_H)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis = 'x')\n",
    "    plt.savefig(title + '.png', dpi = 400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1  Quick linear model for baseline\n",
    "* Use Lasso regression for quick baseline\n",
    "* Mean absolute percentage error (MAPE), mean absolute error (MAE), and the ratio Mean absolute deviation (MAD) are used as evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error, median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso model select the optimized hyperparameters\n",
    "def lasso_best(scaled_train_X, scaled_train_y):\n",
    "    alphas = np.logspace(-6,2,num=50)\n",
    "    #Return numbers spaced evenly on a log scale.\n",
    "    scores = np.empty_like(alphas)\n",
    "    opt_a = float('-inf')\n",
    "    max_score = float('-inf')\n",
    "    for i, a in enumerate(alphas):\n",
    "        lasso = Lasso(max_iter = 100000, tol = 0.01)\n",
    "        lasso.set_params(alpha = a)\n",
    "        lasso.fit(scaled_train_X, scaled_train_y)\n",
    "        scores[i] = lasso.score(scaled_test_X, scaled_test_y) # get scores for test dataset\n",
    "        # lasso.score() Return the coefficient of determination R^2 of the prediction.\n",
    "        # The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).\n",
    "        # A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "        if scores[i] > max_score: # lasso.score is r2 \n",
    "            max_score = scores[i]\n",
    "            opt_a = a\n",
    "            lasso_save = lasso\n",
    "    plt.plot(alphas, scores, color='b', linestyle='dashed', marker='o',markerfacecolor='blue', markersize=6)\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.title('Score vs. Alpha')\n",
    "    plt.savefig('scorealpha.png', dpi = 400)\n",
    "    plt.show()\n",
    "    print ('The optimaized alpha and score of Lasso linear is: ', opt_a, max_score)\n",
    "    print(opt_a)\n",
    "    return opt_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_a = lasso_best(scaled_train_X, scaled_train_y)\n",
    "opt_a_log = lasso_best(scaled_train_X, np.log(scaled_train_y))\n",
    "opt_a_sqrt = lasso_best(scaled_train_X, np.sqrt(scaled_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use  optimal alpha, re-train the model\n",
    "# Linear\n",
    "lasso_f = Lasso(alpha = opt_a)\n",
    "lasso_f.fit(scaled_train_X, scaled_train_y)\n",
    "lasso_pred = lasso_f.predict(scaled_test_X)\n",
    "# Log\n",
    "lasso_f_log = Lasso(alpha = opt_a_log)\n",
    "lasso_f_log.fit(scaled_train_X, np.log(scaled_train_y))\n",
    "lasso_pred_log = lasso_f_log.predict(scaled_test_X)\n",
    "# Sqrt\n",
    "lasso_f_sqrt = Lasso(alpha = opt_a_log)\n",
    "lasso_f_sqrt.fit(scaled_train_X, np.sqrt(scaled_train_y))\n",
    "lasso_pred_sqrt = lasso_f_sqrt.predict(scaled_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yellowbrick\n",
    "from yellowbrick.regressor import PredictionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define MAD_ratio, and evalution result\n",
    "def mean_absolute_devation(arr):\n",
    "    # Calculate the sum of absolute deviation about mean.\n",
    "    absSum = 0\n",
    "    for i in range(0, len(arr)):\n",
    "        absSum = absSum + abs(arr[i] - np.mean(arr))\n",
    "    return absSum / len(arr)\n",
    "\n",
    "def mean_absolute_deviation_ratio(y_true, y_pred):\n",
    "    return mean_absolute_devation(y_pred)/(mean_absolute_devation(y_true)+0.1)\n",
    "\n",
    "def evaluate(test_price, prediction):\n",
    "    MAPE = mean_absolute_percentage_error(test_price,prediction)\n",
    "    print('MAPE of 2019 Airbnb price is {}'.format(MAPE))  \n",
    "    MAE = mean_absolute_error(test_price, prediction)\n",
    "    print('MAE of 2019 Airbnb price is {}'.format(MAE))   \n",
    "    MAD_ratio = mean_absolute_deviation_ratio(test_price,prediction)\n",
    "    print('MAD ratio of prediction in 2019 Airbnb price is {}'.format(MAD_ratio))\n",
    "    r2 = r2_score(test_price, prediction)\n",
    "    print('R^2 of 2019 Airbnb price is {}'.format(r2))\n",
    "    MSLE = mean_squared_log_error(test_price, prediction)\n",
    "    print('MSLE of 2019 Airbnb price is {}'.format(MSLE))\n",
    "    Median = median_absolute_error(test_price, prediction)\n",
    "    print('Median Absolute Error of 2019 Airbnb price is {}'.format(Median))\n",
    "    MSError = mean_squared_error(test_price, prediction)\n",
    "    print('MSE of 2019 Airbnb price is {}'.format(MSError))\n",
    "    return([MAPE, MAE, MAD_ratio, r2, MSLE, Median, MSError])\n",
    " \n",
    "    \n",
    "def plot_diff(test_price, prediction, title1, title2):    # plot the pred vs. actual\n",
    "    plt.plot(prediction,'o', color='red', alpha=0.3, label = 'predicted price')\n",
    "    plt.plot(test_price,'*', color='blue', alpha=0.5, label = 'actual price')\n",
    "    plt.title(title1)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot((prediction - test_price)\n",
    "             ,'v', color='green')\n",
    "    plt.title(title2)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_diff(test_price, prediction, model_name):\n",
    "    plt.plot(test_price, color = \"red\", alpha=0.3, label = 'actual price')\n",
    "    plt.plot(prediction, color = \"green\", alpha=0.5, label = 'predicted_price' )\n",
    "    plt.title(\"Pred vs. Actual in {}\".format(model_name))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_boxplot_diff(test_price, prediction, split_by, cut_offs, model_name, group_name):\n",
    "    plt.style.use('default')\n",
    "    if cut_offs != None:\n",
    "        split_by = pd.cut(split_by, bins = cut_offs[0], labels = cut_offs[1])\n",
    "    residual = test_price - prediction\n",
    "    fig, ax = plt.subplots(figsize = (10, 5))\n",
    "    data = pd.DataFrame({'Residuals':residual, group_name:split_by})\n",
    "    data.boxplot(column = ['Residuals'], by = group_name, ax = ax)\n",
    "    fig.suptitle('Boxplot of Residuals Grouped by ' + model_name)\n",
    "    plt.ylabel('Residuals (Actual - Predicted)')\n",
    "    plt.savefig(model_name + '.png', dpi = 400)\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_regression_diff(test_price, prediction, model_name):\n",
    "    plt.style.use('default')\n",
    "    model_name = 'Actual vs Residuals for ' + model_name\n",
    "    residual = test_price - prediction\n",
    "    coef = np.polyfit(test_price, residual, 1)\n",
    "    function = np.poly1d(coef)\n",
    "    plt.plot(test_price, residual, 'yo', test_price, function(test_price), '--k')\n",
    "    plt.title(model_name)\n",
    "    plt.xlabel('Actual Price')\n",
    "    plt.ylabel('Residual Price')\n",
    "    plt.grid()\n",
    "    plt.ticklabel_format(useOffset=False, style='plain')\n",
    "    plt.savefig(model_name + '_diff.png', dpi = 400)\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_regression_actual(test_price, prediction, model_name):\n",
    "    plt.style.use('default')\n",
    "    model_name = 'Actual vs Prediction for ' + model_name\n",
    "    coef = np.polyfit(test_price, prediction, 1)\n",
    "    function = np.poly1d(coef)\n",
    "    plt.plot(test_price, prediction, 'yo', test_price, function(test_price), '--k')\n",
    "    plt.title(model_name)\n",
    "    plt.xlabel('Actual Price')\n",
    "    plt.ylabel('Prediction Price')\n",
    "    plt.grid()\n",
    "    plt.ticklabel_format(useOffset=False, style='plain')\n",
    "    plt.savefig(model_name + '_actual.png', dpi = 400)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_grid = np.array([[0]*7 for i in range(16)])\n",
    "eval_grid[12,:] = evaluate(scaled_test_y, np.mean(scaled_test_y).repeat(len(scaled_test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pred = np.array([10 if i < 10 else i for i in lasso_pred])\n",
    "lasso_pred_log = np.array([2.3 if i < 2.3 else i for i in lasso_pred_log])\n",
    "lasso_pred_sqrt = np.array([3.16 if i < 3.16 else i for i in lasso_pred_sqrt])\n",
    "eval_grid[0,:] = evaluate(scaled_test_y, lasso_pred)\n",
    "eval_grid[1,:] = evaluate(scaled_test_y, np.exp(lasso_pred_log))\n",
    "eval_grid[2,:] = evaluate(scaled_test_y, np.square(lasso_pred_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_boxplot_diff(scaled_test_y, lasso_pred, scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Lasso Linear Regression (Linear)', 'Price Group')\n",
    "visualize_boxplot_diff(scaled_test_y, np.exp(lasso_pred_log), scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Lasso Linear Regression (Log)', 'Price Group')\n",
    "visualize_boxplot_diff(scaled_test_y, np.square(lasso_pred_sqrt), scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Lasso Linear Regression (Sqrt)', 'Price Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_regression_diff(scaled_test_y, lasso_pred, 'Lasso Linear Regression (Linear)')\n",
    "visualize_regression_diff(scaled_test_y, np.exp(lasso_pred_log), 'Lasso Linear Regression (Log)')\n",
    "visualize_regression_diff(scaled_test_y, np.square(lasso_pred_sqrt), 'Lasso Linear Regression (Sqrt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_regression_actual(scaled_test_y, lasso_pred, 'Lasso Linear Regression (Linear)')\n",
    "visualize_regression_actual(scaled_test_y, np.exp(lasso_pred_log), 'Lasso Linear Regression (Log)')\n",
    "visualize_regression_actual(scaled_test_y, np.square(lasso_pred_sqrt), 'Lasso Linear Regression (Sqrt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important features from linear regression\n",
    "def get_importance_lasso(lasso_f, scaled_train, name):\n",
    "    importance_lr_best = lasso_f.coef_\n",
    "    names_lr_best = scaled_train.loc[:, scaled_train.columns != 'price'].columns.tolist()\n",
    "    df_importantce_lr_best = pd.DataFrame({'Feature':names_lr_best, 'Importance':importance_lr_best})\n",
    "    # plot feature importance\n",
    "    rank_importance_lr_best = df_importantce_lr_best.sort_values('Importance', ascending=False)\n",
    "    plot_feature_importance(rank_importance_lr_best,15, 'steelblue', 0.8, 10, 4, name)\n",
    "get_importance_lasso(lasso_f, scaled_train, 'Feature importance for Lasso (Linear)')\n",
    "get_importance_lasso(lasso_f_log, scaled_train, 'Feature importance for Lasso (Log)')\n",
    "get_importance_lasso(lasso_f_sqrt, scaled_train, 'Feature importance for Lasso (Sqrt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear\n",
    "linear_f = LinearRegression()\n",
    "linear_f.fit(scaled_train_X, scaled_train_y)\n",
    "linear_pred = linear_f.predict(scaled_test_X)\n",
    "# Log \n",
    "linear_f_log = LinearRegression()\n",
    "linear_f_log.fit(scaled_train_X, np.log(scaled_train_y))\n",
    "linear_pred_log = linear_f_log.predict(scaled_test_X)\n",
    "# Sqrt\n",
    "linear_f_sqrt = LinearRegression()\n",
    "linear_f_sqrt.fit(scaled_train_X, np.sqrt(scaled_train_y))\n",
    "linear_pred_sqrt = linear_f_sqrt.predict(scaled_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pred = np.array([10 if i < 10 else i for i in linear_pred])\n",
    "linear_pred_log = np.array([2.3 if i < 2.3 else i for i in linear_pred_log])\n",
    "linear_pred_sqrt = np.array([3.16 if i < 3.16 else i for i in linear_pred_sqrt])\n",
    "eval_grid[13,:] = evaluate(scaled_test_y, linear_pred)\n",
    "eval_grid[14,:] = evaluate(scaled_test_y, np.exp(linear_pred_log))\n",
    "eval_grid[15,:] = evaluate(scaled_test_y, np.square(linear_pred_sqrt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: \" + str(gs.best_score_))\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(param_name + ':' + str(best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parameters = { 'n_neighbors':[10,12,14,16,20,25,30,35,40,45,50,55,60,65,70]}\n",
    "#25, 40, 25 worked best for Linear, Log, and Sqrt respectively\n",
    "parameters = { 'n_neighbors':[20,25,30,35,40] \n",
    "}\n",
    "# Linear\n",
    "Grid_KNN = GridSearchCV(KNeighborsRegressor(),parameters, cv=5)\n",
    "Grid_KNN.fit(scaled_train_X, scaled_train_y)\n",
    "print_grid_search_metrics(Grid_KNN)\n",
    "best_KNN_model = Grid_KNN.best_estimator_\n",
    "# Log\n",
    "Grid_KNN = GridSearchCV(KNeighborsRegressor(),parameters, cv=5)\n",
    "Grid_KNN.fit(scaled_train_X, np.log(scaled_train_y))\n",
    "print_grid_search_metrics(Grid_KNN)\n",
    "best_KNN_model_log = Grid_KNN.best_estimator_\n",
    "# Sqrt\n",
    "Grid_KNN = GridSearchCV(KNeighborsRegressor(),parameters, cv=5)\n",
    "Grid_KNN.fit(scaled_train_X, np.sqrt(scaled_train_y))\n",
    "print_grid_search_metrics(Grid_KNN)\n",
    "best_KNN_model_sqrt = Grid_KNN.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_pred = best_KNN_model.predict(scaled_test_X)\n",
    "knn_pred_log = best_KNN_model_log.predict(scaled_test_X)\n",
    "knn_pred_sqrt = best_KNN_model_sqrt.predict(scaled_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = np.array([10 if i < 10 else i for i in knn_pred])\n",
    "knn_pred_log = np.array([2.3 if i < 2.3 else i for i in knn_pred_log])\n",
    "knn_pred_sqrt = np.array([3.16 if i < 3.16 else i for i in knn_pred_sqrt])\n",
    "eval_grid[3,:] = evaluate(scaled_test_y, knn_pred)\n",
    "eval_grid[4,:] = evaluate(scaled_test_y, np.exp(knn_pred_log))\n",
    "eval_grid[5,:] = evaluate(scaled_test_y, np.square(knn_pred_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_boxplot_diff(scaled_test_y, knn_pred, scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for k-Nearest Neighbors (Linear)', 'Price Group')\n",
    "visualize_boxplot_diff(scaled_test_y, np.exp(knn_pred_log), scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for k-Nearest Neighbors (Log)', 'Price Group')\n",
    "visualize_boxplot_diff(scaled_test_y, np.square(knn_pred_sqrt), scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for k-Nearest Neighbors (Sqrt)', 'Price Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_regression_diff(scaled_test_y, knn_pred, 'k-Nearest Neighbors (Linear)')\n",
    "visualize_regression_diff(scaled_test_y, np.exp(knn_pred_log), 'k-Nearest Neigbors (Log)')\n",
    "visualize_regression_diff(scaled_test_y, np.square(knn_pred_sqrt), 'k-Nearest Neigbor (Sqrt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_regression_actual(scaled_test_y, knn_pred, 'k-Nearest Neighbors (Linear)')\n",
    "visualize_regression_actual(scaled_test_y, np.exp(knn_pred_log), 'k-Nearest Neighbors (Log)')\n",
    "visualize_regression_actual(scaled_test_y, np.square(knn_pred_sqrt), 'k-Nearest Neighbors (Sqrt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get important features from knn\n",
    "from sklearn.inspection import permutation_importance\n",
    "def get_importance_knn(best_KNN_model, scaled_test_X, scaled_test_y, scaled_train, name):\n",
    "    knn_results = permutation_importance(best_KNN_model, scaled_test_X, scaled_test_y, scoring='neg_mean_squared_error')\n",
    "    importance_knn_best = knn_results.importances_mean\n",
    "    names_knn_best = scaled_train.loc[:, scaled_train.columns != 'price'].columns.tolist()\n",
    "    df_importantce_knn_best = pd.DataFrame({'Feature':names_knn_best, 'Importance':importance_knn_best})\n",
    "    # plot feature importance\n",
    "    rank_importance_knn_best = df_importantce_knn_best.sort_values('Importance', ascending=False)\n",
    "    plot_feature_importance(rank_importance_knn_best,15, 'steelblue', 0.8, 10, 4, name)\n",
    "#get_importance_knn(best_KNN_model, scaled_test_X,scaled_test_y,scaled_train,  'Feature importance for kNN (linear)')\n",
    "#get_importance_knn(best_KNN_model_log, scaled_test_X,np.log(scaled_test_y),scaled_train, 'Feature importance for kNN (log)')\n",
    "#get_importance_knn(best_KNN_model_sqrt, scaled_test_X,np.sqrt(scaled_test_y),scaled_train, 'Feature importance for kNN (sqrt)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Linear\n",
    "Grid_SVM = SVR(C = 1)\n",
    "Grid_SVM.fit(scaled_train_X, scaled_train_y)\n",
    "print_grid_search_metrics(Grid_SVM)\n",
    "best_SVM_model = Grid_SVM.best_estimator_\n",
    "# Log\n",
    "Grid_SVM = SVR(C = 1)\n",
    "Grid_SVM.fit(scaled_train_X, np.log(scaled_train_y))\n",
    "print_grid_search_metrics(Grid_SVM)\n",
    "best_SVM_model_log = Grid_SVM.best_estimator_I\n",
    "# Sqrt\n",
    "Grid_SVM = SVR(C = 1)\n",
    "Grid_SVM.fit(scaled_train_X, np.sqrt(scaled_train_y))\n",
    "print_grid_search_metrics(Grid_SVM)\n",
    "best_SVM_model_sqrt = Grid_SVM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = best_SVM_model.predict(scaled_test_X)\n",
    "svm_pred_log = best_SVM_model_log.predict(scaled_test_X)\n",
    "svm_pred_sqrt = best_SVM_model_sqrt.predict(scaled_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pred = np.array([10 if i < 10 else i for i in svm_pred])\n",
    "svm_pred_log = np.array([2.3 if i < 2.3 else i for i in svm_pred_log])\n",
    "svm_pred_sqrt = np.array([3.16 if i < 3.16 else i for i in svm_pred_sqrt])\n",
    "eval_grid[6,:] = evaluate(scaled_test_y, svm_pred)\n",
    "eval_grid[7,:] = evaluate(scaled_test_y, np.exp(svm_pred_log))\n",
    "eval_grid[8,:] = evaluate(scaled_test_y, np.square(svm_pred_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_boxplot_diff(scaled_test_y, svm_pred, scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Support Vector Machine (Linear)', 'Price Group')\n",
    "visualize_boxplot_diff(scaled_test_y, np.exp(svm_pred_log), scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Support Vector Machine (Log)', 'Price Group')\n",
    "visualize_boxplot_diff(scaled_test_y, np.square(svm_pred_sqrt) scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Support Vector Machine (Sqrt)', 'Price Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_regression_diff(scaled_test_y, svm_pred, 'Support Vector Machine (Linear)')\n",
    "visualize_regression_diff(scaled_test_y, np.exp(svm_pred_log), 'Support Vector Machine (Log)')\n",
    "visualize_regression_diff(scaled_test_y, np.square(svm_pred_sqrt), 'Support Vector Machine (Sqrt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_regression_actual(scaled_test_y, svm_pred, 'Support Vector Machine')\n",
    "visualize_regression_actual(scaled_test_y, np.exp(svm_pred_log), 'Support Vector Machine')\n",
    "visualize_regression_actual(scaled_test_y, np.square(svm_pred_sqrt), 'Support Vector Machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important features from SVM\n",
    "def get_importance_SVM(best_SVM_model, scaled_train, name):\n",
    "    importance_svm_best = abs(best_SVM_model.coef_[0])\n",
    "    names_svm_best = scaled_train.loc[:, scaled_train.columns != 'price'].columns.tolist()\n",
    "    df_importantce_svm_best = pd.DataFrame({'Feature':names_svm_best, 'Importance':importance_svm_best})\n",
    "    # plot feature importance\n",
    "    rank_importance_svm_best = df_importantce_svm_best.sort_values('Importance', ascending=False)\n",
    "    plot_feature_importance(rank_importance_svm_best,15, 'steelblue', 0.8, 10, 4, 'Feature importance for SVM')\n",
    "\n",
    "get_importance_SVM(best_SVM_model, scaled_train, 'Feature importance for SVM (Linear)')\n",
    "get_importance_SVM(best_SVM_model_log, scaled_train, 'Feature importance for SVM (Log)')\n",
    "get_importance_SVM(best_SVM_model_sqrt, scaled_train, 'Feature importance for SVM (Sqrt)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [5,10,15,20,30,40],\n",
    "          'max_depth': [20,25,30,40,45,50,55,60]}  \n",
    "  \n",
    "Grid_RF = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, refit = True, verbose = 3, cv =5) \n",
    "Grid_RF.fit(scaled_train_X, scaled_train_y)\n",
    "print_grid_search_metrics(Grid_RF)\n",
    "best_RF_model = Grid_RF.best_estimator_\n",
    "best_RF_model.fit(scaled_train_X, scaled_train_y)\n",
    "\n",
    "Grid_RF = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, refit = True, verbose = 3, cv =5) \n",
    "Grid_RF.fit(scaled_train_X, np.log(scaled_train_y))\n",
    "print_grid_search_metrics(Grid_RF)\n",
    "best_RF_model_log = Grid_RF.best_estimator_\n",
    "best_RF_model_log.fit(scaled_train_X, np.log(scaled_train_y))\n",
    "\n",
    "Grid_RF = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, refit = True, verbose = 3, cv =5) \n",
    "Grid_RF.fit(scaled_train_X, np.sqrt(scaled_train_y))\n",
    "print_grid_search_metrics(Grid_RF)\n",
    "best_RF_model_sqrt = Grid_RF.best_estimator_\n",
    "best_RF_model_sqrt.fit(scaled_train_X, np.sqrt(scaled_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = best_RF_model.predict(scaled_test_X)\n",
    "rf_pred_log = best_RF_model_log.predict(scaled_test_X)\n",
    "rf_pred_sqrt = best_RF_model_sqrt.predict(scaled_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = np.array([10 if i < 10 else i for i in rf_pred])\n",
    "rf_pred_log = np.array([2.3 if i < 2.3 else i for i in rf_pred_log])\n",
    "rf_pred_sqrt = np.array([3.16 if i < 3.16 else i for i in rf_pred_sqrt])\n",
    "eval_grid[9,:] = evaluate(scaled_test_y, rf_pred)\n",
    "eval_grid[10,:] = evaluate(scaled_test_y, np.exp(rf_pred_log))\n",
    "eval_grid[11,:] = evaluate(scaledd_test_y, np.log(rf_pred_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_boxplot_diff(scaled_test_y, rf_pred, scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Random Forest (Linear)', 'Price Group')\n",
    "visualize_boxplot_diff(scaled_test_y, np.exp(rf_pred_log), scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Random Forest (Log)', 'Price Group')\n",
    "visualize_boxplot_diff(scaled_test_y, np.square(rf_pred_sqrt), scaled_test_y, \n",
    "                       [[10, 50, 100, 150, 200, 250, 300, 350, 400, 1000],\n",
    "                      ['10-50','50-00','100-150','150-200','200-250','250-300','300-350','350-400','400-1000']],\n",
    "                      'Price Category for Random Forest (Sqrt)', 'Price Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_regression_diff(scaled_test_y, rf_pred, 'Random Forest (Linear)')\n",
    "visualize_regression_diff(scaled_test_y, np.exp(rf_pred_log), 'Random Forest (Log)')\n",
    "visualize_regression_diff(scaled_test_y, np.square(rf_pred_sqrt), 'Random Forest (Sqrt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_regression_actual(scaled_test_y, rf_pred, 'Random Forest (Linear)')\n",
    "visualize_regression_actual(scaled_test_y, np.exp(rf_pred_log), 'Random Forest (Log)')\n",
    "visualize_regression_actual(scaled_test_y, np.square(rf_pred_sqrt), 'Random Forest (Exp)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importance_rf(best_RF_model, scaled_train, name):\n",
    "    importance_rf_best = best_RF_model.feature_importances_\n",
    "    names_rf_best = scaled_train.loc[:, scaled_train.columns != 'price'].columns.tolist()\n",
    "    df_importantce_rf_best = pd.DataFrame({'Feature':names_rf_best, 'Importance':importance_rf_best})\n",
    "    # plot feature importance\n",
    "    rank_importance_rf_best = df_importantce_rf_best.sort_values('Importance', ascending=False)\n",
    "\n",
    "    plot_feature_importance(rank_importance_rf_best,15, 'steelblue', 0.8, 10, 4, name)\n",
    "get_importance_rf(best_RF_model, scaled_train, 'Feature importance for Random Forest (Linear)')\n",
    "get_importance_rf(best_RF_model_log, scaled_train, 'Feature importance for Random Forest (Log)')\n",
    "get_importance_rf(best_RF_model_sqrt, scaled_train, 'Feature importance for Random Forest (Exp)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = df_test_keep.iloc[:,5:10]\n",
    "neigh.columns = ['Bronx','Brooklyn','Manhattan','Queens','Staten Island']\n",
    "s2 = pd.Series(neigh.columns[np.where(neigh != 0)[1]])\n",
    "visualize_boxplot_diff(scaled_test_y, rf_pred, s2, None,\n",
    "                      'Neighborhood Group for Random Forest', 'Neighborhood Group')\n",
    "visualize_boxplot_diff(scaled_test_y, lasso_pred, s2, None,\n",
    "                      'Neighborhood Group for LASSO', 'Neighborhood Group')\n",
    "visualize_boxplot_diff(scaled_test_y, knn_pred, s2, None,\n",
    "                      'Neighborhood Group for k-Nearest Neighbors', 'Neighborhood Group')\n",
    "visualize_boxplot_diff(scaled_test_y, svm_pred, s2, None,\n",
    "                      'Neighborhood Group for SVM', 'Neighborhood Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s2 = pd.qcut(df_test_keep['minimum_nights'], 6, duplicates = 'drop')\n",
    "fix = 'Minimum Nights '\n",
    "visualize_boxplot_diff(scaled_test_y, rf_pred, s2, None,\n",
    "                      fix + 'for Random Forest', fix)\n",
    "visualize_boxplot_diff(scaled_test_y, lasso_pred, s2, None,\n",
    "                      fix + 'for LASSO', fix)\n",
    "visualize_boxplot_diff(scaled_test_y, knn_pred, s2, None,\n",
    "                      fix +  'for k-Nearest Neighbors', fix)\n",
    "visualize_boxplot_diff(scaled_test_y, svm_pred, s2, None,\n",
    "                      fix +  'for SVM', fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.qcut(scaled_test_y, 10, labels = ['10-50','50-60','60-75','75-90','90-105','105-130','130-155','155-199','199-260','260-1000'], duplicates = 'drop')\n",
    "fix = 'Price Decile '\n",
    "visualize_boxplot_diff(scaled_test_y, rf_pred, s2, None,\n",
    "                      fix + 'for Random Forest', fix)\n",
    "visualize_boxplot_diff(scaled_test_y, lasso_pred, s2, None,\n",
    "                      fix + 'for LASSO', fix)\n",
    "visualize_boxplot_diff(scaled_test_y, knn_pred, s2, None,\n",
    "                      fix +  'for k-Nearest Neighbhors', fix)\n",
    "visualize_boxplot_diff(scaled_test_y, svm_pred, s2, None,\n",
    "                      fix +  'for SVM', fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(eval_grid, columns = ['MAPE', 'MAE', 'MAD_ratio', 'r2_score', 'MSLE', 'Median Absolute Error', 'MSE'],\n",
    "                  index = ['LASSO (Linear)', 'LASSO (Log)', 'LASSO (Sqrt)', 'kNN (Linear)', 'kNN (Log)', 'kNN (Sqrt)', 'SVM (Linear)', 'SVM (Log)', 'SVM (Sqrt)',\n",
    "        'Random Forest (Linear)', 'Random Forest (Log)', 'Random Forest (Sqrt)','Null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (8,5))\n",
    "ax = sns.heatmap(df, annot = True, ax = axes)\n",
    "fig = ax.get_figure()\n",
    "fig.tight_layout()\n",
    "fig.title(\"Evaluation Metrics for Each of the 12 Calculated Models\")\n",
    "fig.savefig(\"Metrics.png\", dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
